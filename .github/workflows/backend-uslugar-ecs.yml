name: Backend - Reuse existing Task Definition (ECR→ECS)

on:
  push:
    branches: [ "main" ]
    paths:
      - "uslugar/backend/**"
      - ".github/workflows/backend-uslugar-ecs.yml"

env:
  AWS_REGION: eu-north-1
  ECR_REPO_BACKEND: uslugar
  ECS_CLUSTER: apps-cluster
  ECS_SERVICE: uslugar-service-2gk1f1mv
  CONTAINER_NAME: uslugar
  # subneti/SG za one-off Fargate task (schema apply)
  MIGRATE_SUBNETS: subnet-0a00f97768705bbcf,subnet-0546fb6cc0ad2cc37
  MIGRATE_SG: sg-084c1e49c9c77aff1

jobs:
  deploy:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: write

    steps:
      - uses: actions/checkout@v4

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - id: ecr-login
        uses: aws-actions/amazon-ecr-login@v2

      # Ako nema package-lock.json, generiraj ga (Dockerfile koristi npm ci)
      - name: Generate package-lock.json (backend)
        working-directory: uslugar/backend
        run: |
          if [ ! -f package-lock.json ]; then
            echo "No package-lock.json found, generating..."
            npm i --package-lock-only
          fi
          head -n 20 package-lock.json || true

      - name: Install jq (for Secrets Manager parsing)
        run: sudo apt-get update && sudo apt-get install -y jq

      # Učitaj DATABASE_URL iz Secrets Managera (za lokalne provjere/prisma get-config u nekim buildovima)
      - name: Load DATABASE_URL from Secrets Manager (for Prisma get-config)
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          DB_SECRET_ARN: ${{ secrets.DB_SECRET_ARN }}
        run: |
          set -euo pipefail

          if [ -z "${DB_SECRET_ARN:-}" ]; then
            echo "ERROR: DB_SECRET_ARN is empty."
            exit 2
          fi

          RAW=$(aws secretsmanager get-secret-value \
                  --region "$AWS_REGION" \
                  --secret-id "$DB_SECRET_ARN" \
                  --query SecretString --output text)

          if echo "$RAW" | jq -e . >/dev/null 2>&1; then
            DATABASE_URL=$(printf %s "$RAW" | jq -r '.DATABASE_URL // .database_url // .url')
          else
            DATABASE_URL="$RAW"
          fi

          if [ -z "${DATABASE_URL:-}" ] || [ "${DATABASE_URL}" = "null" ]; then
            echo "ERROR: DATABASE_URL nije pronađen u secretu."
            exit 3
          fi

          echo "::add-mask::${DATABASE_URL}"
          echo "DATABASE_URL=${DATABASE_URL}" >> "$GITHUB_ENV"
          echo "DATABASE_URL loaded."

      - name: Build & Push image
        env:
          ECR_REGISTRY: ${{ steps.ecr-login.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -f uslugar/backend/Dockerfile.prod \
            -t $ECR_REGISTRY/${{ env.ECR_REPO_BACKEND }}:$IMAGE_TAG uslugar/backend
          docker push $ECR_REGISTRY/${{ env.ECR_REPO_BACKEND }}:$IMAGE_TAG
          echo "IMAGE_URI=$ECR_REGISTRY/${{ env.ECR_REPO_BACKEND }}:$IMAGE_TAG" >> $GITHUB_ENV

      - name: Read current Task Definition
        run: |
          set -euo pipefail
          TD_ARN=$(aws ecs describe-services \
            --cluster "${{ env.ECS_CLUSTER }}" \
            --services "${{ env.ECS_SERVICE }}" \
            --query "services[0].taskDefinition" --output text)
          echo "Using task definition: $TD_ARN"

          aws ecs describe-task-definition --task-definition "$TD_ARN" \
            --query "taskDefinition" --output json > td.json

          # Očisti polja koja se ne smiju slati u register-task-definition
          jq 'del(
            .status,
            .requiresAttributes,
            .compatibilities,
            .revision,
            .registeredAt,
            .registeredBy,
            .deregisteredAt,
            .taskDefinitionArn,
            .tags,
            .inferenceAccelerators
          )' td.json > td_clean.json

      # 🔑 Zamijeni image i postavi ispravan valueFrom za DATABASE_URL (auto: JSON key suffix ili plain ARN)
      - name: Replace image in TD (+ ensure DATABASE_URL secret with correct suffix)
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          DB_SECRET_ARN: ${{ secrets.DB_SECRET_ARN }}
        run: |
          set -euo pipefail

          # 1) Zamijeni image za CONTAINER_NAME
          jq --arg NAME "${{ env.CONTAINER_NAME }}" --arg IMG "${IMAGE_URI}" '
            .containerDefinitions = (.containerDefinitions | map(
              if .name == $NAME then .image = $IMG | . else . end
            ))
          ' td_clean.json > td_tmp.json

          # 2) Odredi VALUE_FROM (ako je tajna JSON s ključem DATABASE_URL => dodaj :DATABASE_URL::
          RAW=$(aws secretsmanager get-secret-value \
                  --region "$AWS_REGION" \
                  --secret-id "$DB_SECRET_ARN" \
                  --query SecretString --output text || true)

          VALUE_FROM="${DB_SECRET_ARN}"
          if echo "$RAW" | jq -e . >/dev/null 2>&1; then
            if [ "$(printf %s "$RAW" | jq -r 'has("DATABASE_URL")')" = "true" ]; then
              VALUE_FROM="${DB_SECRET_ARN}:DATABASE_URL::"
            fi
          fi
          echo "Using valueFrom: $VALUE_FROM"

          # 3) Ubaci/overwrite secrets[] za DATABASE_URL na ciljanom kontejneru
          jq --arg NAME "${{ env.CONTAINER_NAME }}" --arg VF "$VALUE_FROM" '
            .containerDefinitions = (.containerDefinitions | map(
              if .name == $NAME then
                .secrets = (
                  (.secrets // [])
                  | map(select(.name != "DATABASE_URL"))
                  + [{name:"DATABASE_URL", valueFrom:$VF}]
                )
              else . end
            ))
          ' td_tmp.json > td_new.json

          echo "New image & DATABASE_URL secret ensured for '${{ env.CONTAINER_NAME }}'."

      - name: Register new TD revision
        run: |
          set -euo pipefail
          NEW_TD_ARN=$(aws ecs register-task-definition \
            --cli-input-json file://td_new.json \
            --query "taskDefinition.taskDefinitionArn" --output text)
          echo "NEW_TD_ARN=$NEW_TD_ARN" >> $GITHUB_ENV
          echo "Registered: $NEW_TD_ARN"

      - name: Update service to new TD
        run: |
          aws ecs update-service \
            --cluster "${{ env.ECS_CLUSTER }}" \
            --service "${{ env.ECS_SERVICE }}" \
            --task-definition "${NEW_TD_ARN}" \
            --query "service.taskDefinition" --output text

      # ✅ POST-DEPLOY: Apply schema preko one-off taska + dijagnostika
      - name: Apply schema (Prisma db push via one-off task, with diagnostics)
        env:
          SUBNETS: ${{ env.MIGRATE_SUBNETS }}
          SECGRP:  ${{ env.MIGRATE_SG }}
          ASSIGN_PUBLIC_IP: ENABLED
          AWS_REGION: ${{ env.AWS_REGION }}
        run: |
          set -euo pipefail

          # Brzi probe – vidljivost basic toolinga
          cat > probe.json <<'JSON'
          {
            "containerOverrides": [
              {
                "name": "uslugar",
                "command": ["sh","-lc","set -x; which sh || true; node -v || true; npm -v || true; npx -v || true; ls -la node_modules/.bin 2>/dev/null | head -n 50 || true"]
              },
              { "name": "nginx-proxy", "command": ["sh","-lc","tail -f /dev/null"] }
            ]
          }
          JSON

          PROBE_TASK=$(aws ecs run-task \
            --cluster "${{ env.ECS_CLUSTER }}" \
            --launch-type FARGATE \
            --task-definition "${NEW_TD_ARN}" \
            --network-configuration "awsvpcConfiguration={subnets=[${SUBNETS}],securityGroups=[${SECGRP}],assignPublicIp=${ASSIGN_PUBLIC_IP}}" \
            --overrides file://probe.json \
            --region "${AWS_REGION}" \
            --query "tasks[0].taskArn" --output text)

          echo "Probe task: $PROBE_TASK"
          aws ecs wait tasks-stopped --cluster "${{ env.ECS_CLUSTER }}" --tasks "$PROBE_TASK" --region "${AWS_REGION}"
          echo "---- PROBE stoppedReason ----"
          aws ecs describe-tasks --cluster "${{ env.ECS_CLUSTER }}" --tasks "$PROBE_TASK" --region "${AWS_REGION}" \
            --query "tasks[0].stoppedReason" --output text || true
          echo "---- PROBE containers ----"
          aws ecs describe-tasks --cluster "${{ env.ECS_CLUSTER }}" --tasks "$PROBE_TASK" --region "${AWS_REGION}" \
            --query "tasks[0].containers[].{name:name,lastStatus:lastStatus,exitCode:exitCode,reason:reason}" --output table || true

          # Glavni migrate
          cat > overrides.json <<'JSON'
          {
            "containerOverrides": [
              {
                "name": "uslugar",
                "command": ["sh","-lc","npx --yes prisma db push --schema=prisma/schema.prisma && npx --yes prisma migrate status --schema=prisma/schema.prisma"],
                "environment": [
                  { "name": "PRISMA_OPENSSL_VERSION", "value": "3.0.x" }
                ]
              },
              { "name": "nginx-proxy", "command": ["sh","-lc","tail -f /dev/null"] }
            ]
          }
          JSON

          TASK_ARN=$(aws ecs run-task \
            --cluster "${{ env.ECS_CLUSTER }}" \
            --launch-type FARGATE \
            --task-definition "${NEW_TD_ARN}" \
            --network-configuration "awsvpcConfiguration={subnets=[${SUBNETS}],securityGroups=[${SECGRP}],assignPublicIp=${ASSIGN_PUBLIC_IP}}" \
            --overrides file://overrides.json \
            --region "${AWS_REGION}" \
            --query "tasks[0].taskArn" --output text)

          echo "Started task: $TASK_ARN"
          aws ecs wait tasks-stopped --cluster "${{ env.ECS_CLUSTER }}" --tasks "$TASK_ARN" --region "${AWS_REGION}}"

          echo "---- Task stoppedReason ----"
          aws ecs describe-tasks --cluster "${{ env.ECS_CLUSTER }}" --tasks "$TASK_ARN" --region "${AWS_REGION}" \
            --query "tasks[0].stoppedReason" --output text || true

          echo "---- Container breakdown ----"
          aws ecs describe-tasks --cluster "${{ env.ECS_CLUSTER }}" --tasks "$TASK_ARN" --region "${AWS_REGION}" \
            --query "tasks[0].containers[].{name:name,lastStatus:lastStatus,exitCode:exitCode,reason:reason}" --output table || true

          EXIT_CODE=$(aws ecs describe-tasks \
            --cluster "${{ env.ECS_CLUSTER }}" --tasks "$TASK_ARN" --region "${AWS_REGION}" \
            --query "tasks[0].containers[?name=='${{ env.CONTAINER_NAME }}'].exitCode | [0]" --output text)

          echo "Apply schema exit code: ${EXIT_CODE}"

          LOG_GROUP=$(aws ecs describe-task-definition --task-definition "${NEW_TD_ARN}" \
            --query "taskDefinition.containerDefinitions[?name=='${{ env.CONTAINER_NAME }}'].logConfiguration.options.\"awslogs-group\" | [0]" --output text)
          LOG_PREFIX=$(aws ecs describe-task-definition --task-definition "${NEW_TD_ARN}" \
            --query "taskDefinition.containerDefinitions[?name=='${{ env.CONTAINER_NAME }}'].logConfiguration.options.\"awslogs-stream-prefix\" | [0]" --output text)
          TASK_ID=${TASK_ARN##*/}

          if [ -z "$EXIT_CODE" ] || [ "$EXIT_CODE" = "None" ] || [ "$EXIT_CODE" != "0" ]; then
            echo "Prisma db push failed (exit=${EXIT_CODE:-unset})"
            if [ -n "$LOG_GROUP" ] && [ "$LOG_GROUP" != "None" ]; then
              if [ -n "$LOG_PREFIX" ] && [ "$LOG_PREFIX" != "None" ]; then
                aws logs tail "$LOG_GROUP" --log-stream-names "$LOG_PREFIX/${{ env.CONTAINER_NAME }}/$TASK_ID" --since 1h --region "${AWS_REGION}" || \
                aws logs tail "$LOG_GROUP" --since 1h --region "${AWS_REGION}" || true
              else
                aws logs tail "$LOG_GROUP" --since 1h --region "${AWS_REGION}" || true
              fi
            else
              echo "No CloudWatch log group configured for container '${{ env.CONTAINER_NAME }}' in the task definition."
            fi
            exit 1
          fi

          echo "Prisma schema applied successfully."
